{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27bff51",
   "metadata": {},
   "source": [
    "# Script that creates tables for the paper\n",
    "\n",
    "## Table containing best equation for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a25f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# this is a weird fix for some weird error with paths\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9299e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 22\n",
      "{'abalone': '../results/2024-06-17-full-results/results-102\\\\abalone\\\\symbolic_regression_cp.pk', 'airfoil_self_noise': '../results/2024-06-17-full-results/results-102\\\\airfoil_self_noise\\\\symbolic_regression_cp.pk', 'brazilian_houses': '../results/2024-06-17-full-results/results-102\\\\brazilian_houses\\\\symbolic_regression_cp.pk', 'california_housing': '../results/2024-06-17-full-results/results-102\\\\california_housing\\\\symbolic_regression_cp.pk', 'cars': '../results/2024-06-17-full-results/results-102\\\\cars\\\\symbolic_regression_cp.pk', 'concrete_compressive_strength': '../results/2024-06-17-full-results/results-102\\\\concrete_compressive_strength\\\\symbolic_regression_cp.pk', 'fifa': '../results/2024-06-17-full-results/results-102\\\\fifa\\\\symbolic_regression_cp.pk', 'grid_stability': '../results/2024-06-17-full-results/results-102\\\\grid_stability\\\\symbolic_regression_cp.pk', 'health_insurance': '../results/2024-06-17-full-results/results-102\\\\health_insurance\\\\symbolic_regression_cp.pk', 'kin8nm': '../results/2024-06-17-full-results/results-102\\\\kin8nm\\\\symbolic_regression_cp.pk', 'kings_county': '../results/2024-06-17-full-results/results-102\\\\kings_county\\\\symbolic_regression_cp.pk', 'miami_housing': '../results/2024-06-17-full-results/results-102\\\\miami_housing\\\\symbolic_regression_cp.pk', 'Moneyball': '../results/2024-06-17-full-results/results-102\\\\Moneyball\\\\symbolic_regression_cp.pk', 'physiochemical_protein': '../results/2024-06-17-full-results/results-102\\\\physiochemical_protein\\\\symbolic_regression_cp.pk', 'pumadyn32nh': '../results/2024-06-17-full-results/results-102\\\\pumadyn32nh\\\\symbolic_regression_cp.pk', 'QSAR_fish_toxicity': '../results/2024-06-17-full-results/results-102\\\\QSAR_fish_toxicity\\\\symbolic_regression_cp.pk', 'red_wine': '../results/2024-06-17-full-results/results-102\\\\red_wine\\\\symbolic_regression_cp.pk', 'socmob': '../results/2024-06-17-full-results/results-102\\\\socmob\\\\symbolic_regression_cp.pk', 'space_ga': '../results/2024-06-17-full-results/results-102\\\\space_ga\\\\symbolic_regression_cp.pk', 'superconductivity': '../results/2024-06-17-full-results/results-102\\\\superconductivity\\\\symbolic_regression_cp.pk', 'wave_energy': '../results/2024-06-17-full-results/results-102\\\\wave_energy\\\\symbolic_regression_cp.pk', 'white_wine': '../results/2024-06-17-full-results/results-102\\\\white_wine\\\\symbolic_regression_cp.pk'}\n"
     ]
    }
   ],
   "source": [
    "# root folder with the results\n",
    "#results_folder = \"../results/2024-06-07-full-results\"\n",
    "results_folder = \"../results/2024-06-17-full-results/results-102\"\n",
    "pk_file_name = \"symbolic_regression_cp.pk\"\n",
    "\n",
    "# names of the two fitness functions\n",
    "fitness_coverage = \"coverage\"\n",
    "fitness_median = \"median\"\n",
    "\n",
    "# data structures\n",
    "datasets_to_files = {}\n",
    "\n",
    "# recursively walk through all the folders, looking for files\n",
    "for folder, subfolders, files in os.walk(results_folder) :\n",
    "    if pk_file_name in files :\n",
    "        datasets_to_files[os.path.basename(folder)] = os.path.join(folder, pk_file_name)\n",
    "\n",
    "print(\"Number of files: %d\" % len(datasets_to_files))\n",
    "print(datasets_to_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f966c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# right now, the equations are encoded as sympy objects; sympy objects have a method that can\n",
    "# convert them to latex expressions; so, we could manipulate the expression, replacing symbols\n",
    "# with more human-readable symbols. But to do that, we need to build a dictionary of Symbols\n",
    "\n",
    "# and maybe it's actually easier to replace stuff directly inside the latex expression\n",
    "dict_replacement = {}\n",
    "dict_replacement[r\"x_{0}\"] = r\"\\hat{y}\" # x_0 is actually the predicted (normalized) value\n",
    "dict_replacement[r\"x_{1}\"] = r\"\\sigma_d\" # x_1 is the sigmas, based on distance\n",
    "dict_replacement[r\"x_{2}\"] = r\"\\sigma_{std}\" # x_2 is the sigmas, based on standard deviation\n",
    "dict_replacement[r\"x_{3}\"] = r\"\\sigma_{oob}\" # x_3 is the sigmas, based on oob residuals\n",
    "dict_replacement[r\"x_{4}\"] = r\"\\sigma_{var}\" # x_4 is the sigmas, based on variance of predictors in ensemble\n",
    "\n",
    "# all other values are features, so we can just replace them with x_{n-5}\n",
    "# 116 is the maximum number of features appearing among the considered data sets\n",
    "dict_replacement_features = {}\n",
    "for i in range(0, 116) :\n",
    "    dict_replacement_features[\"x_{%d}\" % (i+5)] = \"x_{%d}\" % i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "166cd35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l|l|l|l}\n",
      "\\textbf{Data set name} & \\textbf{Best equation} & \\textbf{Data set name} & \\textbf{Best equation}\\\\ \\hline \\hline\n",
      "\\texttt{abalone} & $e^{\\sigma_{oob}}$ & \\texttt{miami\\_housing} & $\\sigma_d + 4.96 \\sigma_{var}$ \\\\ \\hline\n",
      "\\texttt{airfoil\\_self\\_noise} & $\\sigma_d + \\sigma_{var} + 0.141$ & \\texttt{Moneyball} & $\\sin{\\left(0.971 \\sin{\\left(0.0525 x_{4} + \\sin{\\left(\\cos{\\left(\\cos{\\left(- \\hat{y} + x_{3} + x_{4} \\right)} \\right)} \\right)} \\right)} \\right)}$ \\\\ \\hline\n",
      "\\cellcolor[HTML]{ee82ee}\\texttt{brazilian\\_houses} & \\cellcolor[HTML]{ee82ee}$0.794 + \\frac{0.0106 \\left(\\hat{y} + x_{8}\\right)}{\\sigma_{std}}$ & \\texttt{physiochemical\\_protein} & $\\sigma_{var} + 0.898$ \\\\ \\hline\n",
      "\\cellcolor[HTML]{ee82ee}\\texttt{california\\_housing} & \\cellcolor[HTML]{ee82ee}$\\sigma_{var} + 0.742$ & \\texttt{pumadyn32nh} & $0.0495 x_{25} + 1.15$ \\\\ \\hline\n",
      "\\texttt{cars} & $\\sigma_{oob} + 0.0761$ & \\texttt{QSAR\\_fish\\_toxicity} & $\\sigma_d + e^{\\sigma_{std} \\sin{\\left(2.26 x_{1} \\right)}}$ \\\\ \\hline\n",
      "\\texttt{concrete\\_compressive\\_strength} & $\\sigma_{var} + 0.476$ & \\texttt{red\\_wine} & $\\sigma_{var} + 1.13$ \\\\ \\hline\n",
      "\\cellcolor[HTML]{ee82ee}\\texttt{fifa} & \\cellcolor[HTML]{ee82ee}$4.72 \\sigma_{oob}$ & \\texttt{socmob} & $\\sigma_{var} e^{- x_{2} \\cos{\\left(x_{0} \\right)} - \\frac{0.0119}{x_{0} x_{1}}} + \\sin{\\left(0.593 \\hat{y} + 0.338 \\right)}$ \\\\ \\hline\n",
      "\\texttt{grid\\_stability} & $\\sigma_{oob} + 0.373$ & \\texttt{space\\_ga} & $\\sigma_{oob} + 0.641$ \\\\ \\hline\n",
      "\\texttt{health\\_insurance} & $\\sigma_{std} + 1.08$ & \\texttt{superconductivity} & $\\sigma_{oob} + 0.291$ \\\\ \\hline\n",
      "\\texttt{kin8nm} & $\\sigma_{oob} + 0.645$ & \\texttt{wave\\_energy} & $\\sigma_{oob} + 0.450$ \\\\ \\hline\n",
      "\\texttt{kings\\_county} & $\\log{\\left(120. \\sigma_{var} \\right)}$ & \\texttt{white\\_wine} & $e^{1.45 \\sigma_{var}}$ \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# new: add a part that also checks whether the approach is dominated or the only one\n",
    "# and colors the cells corresponding to that data set accordingly\n",
    "from check_pareto_optimality import is_dominated # local library\n",
    "\n",
    "# utility function, to avoid cutting and pasting the same code everywhere\n",
    "def check_dominance_on_data_set(df, dataset_name, fitness_1, fitness_2) :\n",
    "    # get the data set row with that particular data set name\n",
    "    row = df[df[\"dataset_name\"] == dataset_name].iloc[0]\n",
    "    fitness_columns = [c for c in df.columns if c.endswith(fitness_1) or c.endswith(fitness_2)]\n",
    "    \n",
    "    # get the methods names and the associated fitness columns\n",
    "    methods = dict()\n",
    "    for fc in fitness_columns :\n",
    "        if fc.find(fitness_1) != -1 :\n",
    "            method = fc[:-len(fitness_1)-1]\n",
    "        elif fc.find(fitness_2) != -1 :\n",
    "            method = fc[:-len(fitness_2)-1]\n",
    "\n",
    "        if method not in methods :\n",
    "            methods[method] = []\n",
    "        methods[method].append(fc)\n",
    "        \n",
    "    # generate points to be compared with the Pareto dominance, and check them \n",
    "    non_dominated_methods = []\n",
    "    for method in methods :\n",
    "        method_point = (row[methods[method][0]], row[methods[method][1]])\n",
    "        other_points = [(row[methods[other_method][0]], row[methods[other_method][1]]) \n",
    "                        for other_method in methods if other_method != method]\n",
    "\n",
    "        is_method_point_dominated = False\n",
    "        for point in other_points :\n",
    "            if is_dominated(method_point, point) :\n",
    "                is_method_point_dominated = True\n",
    "                \n",
    "        if is_method_point_dominated == False :\n",
    "            non_dominated_methods.append(method)\n",
    "    \n",
    "    # debugging\n",
    "    #print(dataset_name + \": \" + str(non_dominated_methods))\n",
    "    return non_dominated_methods\n",
    "\n",
    "# we also need to read the file with all the results\n",
    "df_results = pd.read_csv(os.path.join(results_folder, \"results.csv\"))\n",
    "\n",
    "# this part takes for granted that we have a total of 22 data sets,\n",
    "# so that we can create two columns of 11 data sets\n",
    "latex_table = r\"\\begin{tabular}{l|l|l|l}\" + \"\\n\" \n",
    "latex_table += r\"\\textbf{Data set name} & \\textbf{Best equation} & \\textbf{Data set name} & \\textbf{Best equation}\\\\ \\hline \\hline\" + \"\\n\"\n",
    "\n",
    "# list of keys in the dictionary\n",
    "datasets = [key for key in datasets_to_files]\n",
    "\n",
    "for i in range(0, 11) :\n",
    "    # columns to the left\n",
    "    dataset_left = datasets[i]\n",
    "    # first, check if the approach is dominated\n",
    "    non_dominated_methods = check_dominance_on_data_set(df_results, dataset_left, fitness_coverage, fitness_median)\n",
    "    # set cell color\n",
    "    left_cell_color = \"\"\n",
    "    if \"symbolic_regression_cp\" not in non_dominated_methods :\n",
    "        left_cell_color = r\"\\cellcolor[HTML]{ee82ee}\"\n",
    "    elif \"symbolic_regression_cp\" in non_dominated_methods and len(non_dominated_methods) == 1 :\n",
    "        left_cell_color = r\"\\cellcolor[HTML]{ccff00}\"\n",
    "    # add data set name\n",
    "    # for the data set name, we need to escape all \"_\" with \"\\_\"\n",
    "    latex_table += left_cell_color + r\"\\texttt{\" + dataset_left.replace(\"_\", r\"\\_\") + r\"} & \"\n",
    "    # add equation\n",
    "    sr_left = pickle.load(open(datasets_to_files[dataset_left], \"rb\"))\n",
    "    equation = sr_left.latex()\n",
    "    # replacement of variables in two steps, to avoid issues with x_%d\n",
    "    for key, value in dict_replacement.items() :\n",
    "        equation = equation.replace(key, value)\n",
    "    for key, value in dict_replacement_features.items() :\n",
    "        equation = equation.replace(key, value)\n",
    "    latex_table += left_cell_color + r\"$\" + equation + r\"$\" + r\" & \"\n",
    "    \n",
    "    # columns to the right\n",
    "    dataset_right = datasets[i+11]\n",
    "    # first, check if the approach is dominated\n",
    "    non_dominated_methods = check_dominance_on_data_set(df_results, dataset_right, fitness_coverage, fitness_median)\n",
    "    # set cell color\n",
    "    right_cell_color = \"\"\n",
    "    if \"symbolic_regression_cp\" not in non_dominated_methods :\n",
    "        right_cell_color = r\"\\cellcolor[HTML]{ee82ee}\"\n",
    "    elif \"symbolic_regression_cp\" in non_dominated_methods and len(non_dominated_methods) == 1 :\n",
    "        right_cell_color = r\"\\cellcolor[HTML]{ccff00}\"\n",
    "    # add data set name\n",
    "    # for the data set name, we need to escape all \"_\" with \"\\_\"\n",
    "    latex_table += right_cell_color + r\"\\texttt{\" + dataset_right.replace(\"_\", r\"\\_\") + r\"} & \"\n",
    "    # add equation\n",
    "    sr_right = pickle.load(open(datasets_to_files[dataset_right], \"rb\"))\n",
    "    equation = sr_right.latex()\n",
    "    # replacement of variables in two steps, to avoid issues with x_%d\n",
    "    for key, value in dict_replacement.items() :\n",
    "        equation = equation.replace(key, value)\n",
    "    for key, value in dict_replacement_features.items() :\n",
    "        equation = equation.replace(key, value)\n",
    "    latex_table += right_cell_color + r\"$\" + equation + r\"$\" + r\" \\\\ \\hline\" + \"\\n\"\n",
    "\n",
    "latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3286cb0",
   "metadata": {},
   "source": [
    "## Table with longer comparison between methods\n",
    "So, this table will be 22 (data sets) x 2 (criteria); x 7 (methods). In each row, we report if a method is the best (+), the worst (-) or neither (.) for each of the two criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3daa0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l|l|l|l|l|l|l|l|l}\n",
      "\\textbf{Data set name} & \\textbf{Metric} & \\textbf{$SCP$} & \\textbf{$NCP_d$} & \\textbf{$NCP_{std}$} & \\textbf{$NCP_{oob}$} & \\textbf{$NCP_{var}$} & \\textbf{$MCP$} & \\textbf{$SRCP$} \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{abalone}} & Coverage & 0.9474 & 0.9502 & 0.9512 & 0.9455 & \\cellcolor[HTML]{ee82ee}0.9311 & 0.9483 & \\cellcolor[HTML]{ccff00} 0.9522 \\\\ \\cline{2-9} \n",
      " & Median & 2.9545 & 3.2021 & \\cellcolor[HTML]{ee82ee}3.6647 & 3.3293 & 2.7972 & 2.6755 & \\cellcolor[HTML]{ccff00} 2.6284 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{airfoil\\_self\\_noise}} & Coverage & 0.9362 & 0.9388 & \\cellcolor[HTML]{ccff00} 0.9468 & 0.9441 & \\cellcolor[HTML]{ee82ee}0.8989 & 0.9282 & 0.9441 \\\\ \\cline{2-9} \n",
      " & Median & 1.1607 & 1.4426 & \\cellcolor[HTML]{ee82ee}1.6024 & 1.5573 & 1.0324 & 1.1157 & \\cellcolor[HTML]{ccff00} 0.9472 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{brazilian\\_houses}} & Coverage & 0.9577 & 0.9562 & 0.9581 & \\cellcolor[HTML]{ee82ee}0.9540 & 0.9600 & \\cellcolor[HTML]{ccff00} 0.9727 & 0.9633 \\\\ \\cline{2-9} \n",
      " & Median & \\cellcolor[HTML]{ee82ee}0.4947 & 0.4813 & 0.3420 & 0.2937 & 0.4858 & 0.3453 & \\cellcolor[HTML]{ccff00} 0.2594 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{california\\_housing}} & Coverage & 0.9531 & 0.9547 & 0.9521 & \\cellcolor[HTML]{ee82ee}0.9514 & 0.9554 & \\cellcolor[HTML]{ccff00} 0.9663 & 0.9525 \\\\ \\cline{2-9} \n",
      " & Median & 1.9542 & \\cellcolor[HTML]{ee82ee}2.3276 & 1.8447 & 1.6705 & 1.4844 & 1.7037 & \\cellcolor[HTML]{ccff00} 1.3536 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{cars}} & Coverage & 0.9303 & \\cellcolor[HTML]{ccff00} 0.9751 & 0.9502 & 0.9453 & 0.9701 & 0.9602 & \\cellcolor[HTML]{ee82ee}0.9254 \\\\ \\cline{2-9} \n",
      " & Median & 1.0866 & \\cellcolor[HTML]{ee82ee}5.2368 & 1.2290 & 0.7567 & 0.9936 & 1.0866 & \\cellcolor[HTML]{ccff00} 0.6614 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{concrete\\_compressive\\_strength}} & Coverage & 0.9264 & 0.9574 & 0.9535 & 0.9651 & \\cellcolor[HTML]{ccff00} 0.9806 & 0.9302 & \\cellcolor[HTML]{ee82ee}0.9147 \\\\ \\cline{2-9} \n",
      " & Median & 1.2917 & \\cellcolor[HTML]{ee82ee}2.0088 & 1.7034 & 1.6180 & 1.6667 & 1.2881 & \\cellcolor[HTML]{ccff00} 0.9751 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{fifa}} & Coverage & 0.9545 & 0.9495 & \\cellcolor[HTML]{ee82ee}0.9395 & \\cellcolor[HTML]{ee82ee}0.9395 & 0.9452 & \\cellcolor[HTML]{ccff00} 0.9568 & \\cellcolor[HTML]{ee82ee}0.9395 \\\\ \\cline{2-9} \n",
      " & Median & \\cellcolor[HTML]{ee82ee}1.8810 & 1.6280 & 0.5688 & 0.5400 & 0.5754 & 0.5692 & \\cellcolor[HTML]{ccff00} 0.5399 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{grid\\_stability}} & Coverage & 0.9552 & 0.9424 & 0.9432 & \\cellcolor[HTML]{ccff00} 0.9560 & \\cellcolor[HTML]{ee82ee}0.9360 & 0.9520 & 0.9540 \\\\ \\cline{2-9} \n",
      " & Median & 1.3653 & \\cellcolor[HTML]{ee82ee}1.5484 & 1.4467 & 1.3390 & 1.4780 & 1.3759 & \\cellcolor[HTML]{ccff00} 1.2266 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{health\\_insurance}} & Coverage & \\cellcolor[HTML]{ee82ee}0.9481 & 0.9582 & 0.9510 & 0.9515 & 0.9542 & \\cellcolor[HTML]{ccff00} 0.9623 & \\cellcolor[HTML]{ee82ee}0.9481 \\\\ \\cline{2-9} \n",
      " & Median & 3.3151 & \\cellcolor[HTML]{ee82ee}5.7595 & 3.6869 & 4.2658 & 5.0377 & 3.6209 & \\cellcolor[HTML]{ccff00} 3.2132 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{kin8nm}} & Coverage & 0.9482 & 0.9526 & \\cellcolor[HTML]{ee82ee}0.9424 & 0.9507 & 0.9458 & 0.9463 & \\cellcolor[HTML]{ccff00} 0.9551 \\\\ \\cline{2-9} \n",
      " & Median & 2.1733 & \\cellcolor[HTML]{ee82ee}2.7016 & 2.3705 & 2.0131 & 2.3174 & 2.1190 & \\cellcolor[HTML]{ccff00} 2.0097 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{kings\\_county}} & Coverage & \\cellcolor[HTML]{ee82ee}0.9524 & 0.9556 & 0.9617 & 0.9563 & 0.9574 & \\cellcolor[HTML]{ccff00} 0.9684 & 0.9552 \\\\ \\cline{2-9} \n",
      " & Median & \\cellcolor[HTML]{ee82ee}1.4712 & 1.1274 & 1.0826 & 0.9722 & \\cellcolor[HTML]{ccff00} 0.7327 & 0.9059 & 0.9615 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{miami\\_housing}} & Coverage & 0.9526 & 0.9518 & 0.9475 & 0.9500 & \\cellcolor[HTML]{ee82ee}0.9388 & \\cellcolor[HTML]{ccff00} 0.9701 & 0.9440 \\\\ \\cline{2-9} \n",
      " & Median & \\cellcolor[HTML]{ee82ee}1.1928 & 0.8502 & 0.5071 & 0.5355 & \\cellcolor[HTML]{ccff00} 0.3968 & 0.5779 & 0.5633 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{Moneyball}} & Coverage & 0.9253 & \\cellcolor[HTML]{ccff00} 0.9805 & 0.9351 & 0.9448 & 0.9448 & 0.9448 & \\cellcolor[HTML]{ee82ee}0.9156 \\\\ \\cline{2-9} \n",
      " & Median & 1.0988 & \\cellcolor[HTML]{ee82ee}3.3098 & 1.4842 & 1.4414 & 1.7583 & 1.1847 & \\cellcolor[HTML]{ccff00} 1.0084 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{physiochemical\\_protein}} & Coverage & 0.9484 & \\cellcolor[HTML]{ee82ee}0.9480 & 0.9508 & 0.9496 & 0.9493 & \\cellcolor[HTML]{ccff00} 0.9580 & 0.9514 \\\\ \\cline{2-9} \n",
      " & Median & 2.6304 & 2.4417 & \\cellcolor[HTML]{ee82ee}2.9550 & 2.3881 & \\cellcolor[HTML]{ccff00} 1.9352 & 2.3144 & 2.2510 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{pumadyn32nh}} & Coverage & 0.9468 & 0.9458 & 0.9580 & \\cellcolor[HTML]{ccff00} 0.9639 & 0.9526 & 0.9526 & \\cellcolor[HTML]{ee82ee}0.9448 \\\\ \\cline{2-9} \n",
      " & Median & 2.3860 & 2.7065 & 2.8763 & \\cellcolor[HTML]{ee82ee}3.0634 & 2.9467 & 2.5839 & \\cellcolor[HTML]{ccff00} 2.3213 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{QSAR\\_fish\\_toxicity}} & Coverage & \\cellcolor[HTML]{ccff00} 0.9868 & 0.9604 & 0.9824 & 0.9648 & 0.9559 & 0.9780 & \\cellcolor[HTML]{ee82ee}0.9207 \\\\ \\cline{2-9} \n",
      " & Median & 3.4230 & 3.2027 & 3.4439 & \\cellcolor[HTML]{ee82ee}4.5222 & 3.5589 & 3.7275 & \\cellcolor[HTML]{ccff00} 1.9548 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{red\\_wine}} & Coverage & 0.9550 & \\cellcolor[HTML]{ccff00} 0.9625 & 0.9550 & 0.9525 & 0.9575 & 0.9600 & \\cellcolor[HTML]{ee82ee}0.9500 \\\\ \\cline{2-9} \n",
      " & Median & 3.4234 & \\cellcolor[HTML]{ee82ee}4.5759 & 3.2935 & 3.4862 & 3.5041 & 3.7128 & \\cellcolor[HTML]{ccff00} 3.0421 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{socmob}} & Coverage & 0.9412 & \\cellcolor[HTML]{ccff00} 0.9585 & 0.9550 & \\cellcolor[HTML]{ee82ee}0.9377 & 0.9550 & 0.9550 & 0.9550 \\\\ \\cline{2-9} \n",
      " & Median & \\cellcolor[HTML]{ee82ee}1.5951 & 1.5285 & 0.5835 & 0.5806 & 0.3293 & 0.7478 & \\cellcolor[HTML]{ccff00} 0.3265 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{space\\_ga}} & Coverage & 0.9614 & 0.9575 & 0.9601 & \\cellcolor[HTML]{ccff00} 0.9678 & \\cellcolor[HTML]{ee82ee}0.9511 & 0.9665 & 0.9562 \\\\ \\cline{2-9} \n",
      " & Median & 2.4853 & \\cellcolor[HTML]{ee82ee}3.5980 & 2.9231 & 3.0588 & 2.8941 & 2.4853 & \\cellcolor[HTML]{ccff00} 2.0549 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{superconductivity}} & Coverage & 0.9528 & 0.9492 & \\cellcolor[HTML]{ee82ee}0.9464 & 0.9481 & 0.9466 & \\cellcolor[HTML]{ccff00} 0.9626 & 0.9518 \\\\ \\cline{2-9} \n",
      " & Median & 1.3232 & \\cellcolor[HTML]{ee82ee}4.9142 & 0.7834 & 0.7384 & \\cellcolor[HTML]{ccff00} 0.5328 & 0.9699 & 0.9111 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{wave\\_energy}} & Coverage & 0.9529 & \\cellcolor[HTML]{ee82ee}0.9479 & 0.9489 & 0.9519 & 0.9516 & 0.9531 & \\cellcolor[HTML]{ccff00} 0.9535 \\\\ \\cline{2-9} \n",
      " & Median & 1.7184 & \\cellcolor[HTML]{ee82ee}2.9430 & 1.9980 & 1.6872 & 1.8567 & 1.6691 & \\cellcolor[HTML]{ccff00} 1.5973 \\\\ \\hline \\hline\n",
      "\\multirow{2}{*}{\\texttt{white\\_wine}} & Coverage & 0.9592 & 0.9584 & \\cellcolor[HTML]{ee82ee}0.9461 & 0.9502 & \\cellcolor[HTML]{ccff00} 0.9665 & 0.9608 & 0.9600 \\\\ \\cline{2-9} \n",
      " & Median & 2.9805 & 3.2859 & \\cellcolor[HTML]{ee82ee}3.6857 & 3.2506 & 2.9687 & 3.1553 & \\cellcolor[HTML]{ccff00} 2.7576 \\\\ \\hline \\hline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# beginning of the table and header\n",
    "latex_table = r\"\\begin{tabular}{l|l|l|l|l|l|l|l|l}\" + \"\\n\" \n",
    "latex_table += r\"\\textbf{Data set name} & \\textbf{Metric} & \\textbf{$SCP$} & \\textbf{$NCP_d$} & \\textbf{$NCP_{std}$}\" \n",
    "latex_table += r\" & \\textbf{$NCP_{oob}$} & \\textbf{$NCP_{var}$} & \\textbf{$MCP$} & \\textbf{$SRCP$} \\\\ \\hline \\hline\" + \"\\n\"\n",
    "\n",
    "# load CSV with results\n",
    "df = pd.read_csv(os.path.join(results_folder, \"results.csv\"))\n",
    "# sort rows by data set name\n",
    "df = df.sort_values(by=\"dataset_name\", key=lambda col: col.str.lower()) # compare lowercase letters\n",
    "# select columns with fitness values\n",
    "columns_coverage = [c for c in df.columns if c.endswith(fitness_coverage)]\n",
    "columns_median = [c for c in df.columns if c.endswith(fitness_median)]\n",
    "# get the names of the different methods, just to check that we are in the good order\n",
    "method_names = [ c[:-len(fitness_median)-1] for c in columns_median if c.endswith(fitness_median)]\n",
    "#print(\"Methods:\", method_names) # looks correct, we can just pick them in order\n",
    "\n",
    "for index, row in df.iterrows() :\n",
    "    # get the name of the data set\n",
    "    dataset_name = row[\"dataset_name\"]\n",
    "    # escape it and put it in the correct latex format\n",
    "    latex_table += r\"\\multirow{2}{*}{\"\n",
    "    latex_table += r\"\\texttt{\" + dataset_name.replace(\"_\", r\"\\_\") + r\"}} \"\n",
    "    \n",
    "    # first sub-row: coverage; find the best (highest) value\n",
    "    latex_table += \"& Coverage \"\n",
    "    coverage_values = row[columns_coverage].values\n",
    "    #print(coverage_values)\n",
    "    # get the index(es) of the highest value(s)\n",
    "    coverage_best = np.where(coverage_values == np.max(coverage_values))[0]\n",
    "    coverage_worst = np.where(coverage_values == np.min(coverage_values))[0]\n",
    "    # iterate over the columns, and plot the appropriate stuff\n",
    "    for i in range(0, len(method_names)) :\n",
    "        latex_table += r\"& \"\n",
    "        # if it's the best or the worst, color it appropriately\n",
    "        if i in coverage_best :\n",
    "            latex_table += r\"\\cellcolor[HTML]{ccff00} \"\n",
    "        elif i in coverage_worst :\n",
    "            latex_table += r\"\\cellcolor[HTML]{ee82ee}\"\n",
    "        latex_table += \"%.4f\" % coverage_values[i] + \" \"\n",
    "        \n",
    "    # second sub-row: median\n",
    "    latex_table += r\"\\\\ \\cline{2-9} \" + \"\\n\"\n",
    "    latex_table += r\" & Median \"\n",
    "    median_values = row[columns_median].values\n",
    "    # get the index(es) of the best (lowest) and worst (highest) values\n",
    "    median_best = np.where(median_values == np.min(median_values))[0]\n",
    "    median_worst = np.where(median_values == np.max(median_values))[0]\n",
    "    # iterate over the columns, and plot the appropriate stuff\n",
    "    for i in range(0, len(method_names)) :\n",
    "        latex_table += r\"& \"\n",
    "        if i in median_best :\n",
    "            latex_table += r\"\\cellcolor[HTML]{ccff00} \"\n",
    "        elif i in median_worst :\n",
    "            latex_table += r\"\\cellcolor[HTML]{ee82ee}\"\n",
    "        latex_table += \"%.4f\" % median_values[i] + \" \"\n",
    "        \n",
    "    # on to the next row\n",
    "    latex_table += r\"\\\\ \\hline \\hline\" + \"\\n\"\n",
    "\n",
    "# end of the table\n",
    "latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6ece06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "array = [1, 2, 3, 1, 3, 3]\n",
    "print(np.argmax(array, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3f862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
